# AiAutoDebateConsole

Система для проведения автоматизированных дебатов между двумя языковыми моделями (LLM), запущенными локально через "LM Studio API".

Реализовано два режима работы:

* **Бесконечные дебаты** — модели спорят между собой без остановки, пока пользователь не прервет.
* **Синхронный режим** — модели отвечают параллельно на вопрос пользователя, не ведя диалог.

---

## 2. Основные возможности

* Подключение к двум LM Studio API по разным IP/портам.
* Автоматическая проверка доступности ботов и получение их моделей.
* Логирование всех диалогов и системных сообщений.
* Подсчет времени ответа и количества использованных токенов.
* Цветовое отображение реплик в консоли (для наглядности).
* Проверка валидности ответов (избегание пустых, односложных и повторяющихся сообщений).
* Возможность принудительного завершения дебатов клавишей `S`.

Стабильные модели.

gemma-3n-e4b-it-text - Я — большая языковая модель, разработанная компанией Google.

google/gemma-3-12b-  Я Gemma, большая языковая модель от Google DeepMind. Я — open-weights модель, что значит, я широко доступна для использования. 

google/gemma-3-27b - Я Gemma, большая языковая модель, разработанная командой Gemma в Google DeepMind.

---

## 3. Архитектура проекта

### 3.1. Основные модули

* **Главный файл:** `debates.py`
* **Основные функции:**

  * `check_bots_status()` — проверка доступности API ботов.
  * `ask_ai()` — отправка сообщения боту и получение ответа.
  * `is_valid_response()` — фильтрация бессмысленных/повторных ответов.
  * `infinite_debate()` — режим бесконечных дебатов.
  * `synchronous_mode()` — режим синхронных ответов на вопрос.
  * `main()` — главное меню программы.

### 3.2. Взаимодействие с API

Запрос формируется в формате **OpenAI Chat Completions API**:

```json
{
  "model": "название_модели",
  "messages": [
    {"role": "system", "content": "инструкции"},
    {"role": "user", "content": "сообщение"}
  ],
  "temperature": 0.7,
  "max_tokens": 300,
  "stop": ["\n\n", "###", "Пользователь:", "User:"]
}
```

---

## 4. Установка и запуск

### 4.1. Требования

* Python **3.10+**

* Установленные зависимости:

  ```bash
  pip install requests colorama
  ```

* Запущенные два LM Studio API-сервера на разных IP/портах.
  Пример:

  * Bot1: `http://192.168.8.87:12345/v1/chat/completions`
  * Bot2: `http://192.168.8.89:1234/v1/chat/completions`

### 4.2. Запуск

```bash
python debates.py
```

---

## 5. Использование

### 5.1. Главное меню

При старте программа проверяет доступность ботов и выводит их статус.
Меню:

```
1. Бесконечные дебаты
2. Синхронный режим
3. Выход
```

### 5.2. Бесконечные дебаты

* Пользователь вводит тему дискуссии.
* Боты по очереди высказываются, реагируя на предыдущие реплики.
* Можно завершить, введя `S` в консоли.
* Если подряд несколько ответов признаны невалидными, система напоминает моделям об условиях.

### 5.3. Синхронный режим

* Пользователь задает вопрос.
* Оба бота параллельно отвечают на него.
* История не сохраняется — только текущий вопрос/ответ.
* Выход — команда `S`.

---

## 6. Логирование

Программа сохраняет логи в два файла:

* `infinite_debate_dialog.log` или `synchronous_mode_dialog.log` — реплики дебатов.
* `system.log` — служебные сообщения, статистика ответов, ошибки.

Пример записи в `system.log`:

```json
AI_RESPONSE_DATA: {
  "bot": "Bot2",
  "response_time": 8.86,
  "tokens_used": 24,
  "completion_tokens": 12,
  "prompt_tokens": 12,
  "timestamp": "2025-08-31T16:39:04.079",
  "model": "gemma-3-4",
  "finish_reason": "stop"
}
```

---

## 7. Валидация ответов

Функция `is_valid_response()` отсекает:

* пустые/короткие ответы (<5 слов),
* повтор последних 3 реплик,
* бессмысленные фразы («да», «нет», «я не знаю»),
* незаконченное предложение (если нет `.`/`!`/`?` в конце).

---

## 8. Пример работы

### 8.1. Запуск

```
=== AI ДЕБАТЫ ===
1. Бесконечные дебаты
2. Синхронный режим
3. Выход
Bot1: Online (Модель: gemma-3-4, IP: 192.168.8.87)
Bot2: Online (Модель: gpt-oss-20b, IP: 192.168.8.89)
